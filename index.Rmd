---
title: "Opiods in United States"
css: style.css
output:
  html_document:
    self_contained: yes
    code_download: yes
    highlight: tango
    number_sections: no
    theme: cosmo
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
  word_document:
    toc: yes

---

<style>
#TOC {
  background: url("https://opencasestudies.github.io/img/logo.jpg");
  background-size: contain;
  padding-top: 240px !important;
  background-repeat: no-repeat;
}
</style>


<!-- Open all links in new tab-->  
<base target="_blank"/> 

```{r setup, include=FALSE}
knitr::opts_chunk$set(include = TRUE, comment = NA, echo = TRUE,
                      message = FALSE, warning = FALSE, cache = FALSE,
                      fig.align = "center", out.width = '90%')
library(here)
library(knitr)
```

#### {.outline }
```{r, echo=FALSE}
knitr::include_graphics(here("img",
                             "API.png"))
```
####

#### {.disclaimer_block}

**Disclaimer**: The purpose of the [Open Case Studies](https://opencasestudies.github.io){target="_blank"} project is **to demonstrate the use of various data science methods, tools, and software in the context of messy, real-world data**. A given case study does not cover all aspects of the research process, is not claiming to be the most appropriate way to analyze a given data set, and should not be used in the context of making policy decisions without external consultation from scientific experts. 

####

#### {.license_block}

This work is licensed under the Creative Commons Attribution-NonCommercial 3.0 [(CC BY-NC 3.0)](https://creativecommons.org/licenses/by-nc/3.0/us/){target="_blank"} United States License.

####

#### {.reference_block}

To cite this case study please use:

Wright, Carrie, and Ontiveros, Michael and Jager, Leah and Taub, Margaret and Hicks, Stephanie. (2020). https://opencasestudies.github.io/ocs-bp-opioid-rural-urban/ocs_pop.html. Opioids in the United States (Version v1.0.0).

avocado update url
####

# **Motivation**
*** 

Washington Post case study:
- Question: How did opioid prescription rates differ by region over time around the US from 2006-2012?
- Description: We will evaluate prescription rates of opioid pain medication across states/counties from 2006-2012.  We will investigate how rural and urban areas differ for prescription rates. We will reference work like this as our motivation: https://www.cdc.gov/mmwr/volumes/68/wr/mm6802a1.htm?s_cid=mm6802a1_w
- Why is this important? This analysis demonstrates how different regions of the country may have been more at risk for opioid addiction crises due to differing rates of opioid prescription. This will help inform students about how evidence-based intervention decisions are made in this area.
- Data:  The data is now obtainable from an R package called arcos. In addition we will use information about state and county urbanization estimates from here: https://www.census.gov/programs-surveys/geography/guidance/geo-areas/urban-rural/2010-urban-rural.html
- Major Data Science Objectives:
1) loading data from data package
2) wrangling - joining dplyr
3) map visualization - ggplot /maps/mapdata/ggmap
- Statistics objectives: Linear regression analysis to evaluate the association of urbanization/population density and opioid prescription rates over time.

This case study is motivated by this [article](https://www.cdc.gov/mmwr/volumes/68/wr/mm6802a1.htm?s_cid=mm6802a1_w):

#### {.reference_block}

García, M. C. et al. Opioid Prescribing Rates in Nonmetropolitan and Metropolitan Counties Among Primary Care Providers Using an Electronic Health Record System — United States, 2014–2017. MMWR Morb. Mortal. Wkly. Rep. 68, 25–30 (2019). DOI: [http://dx.doi.org/10.15585/mmwr.mm6802a1](http://dx.doi.org/10.15585/mmwr.mm6802a1)

####

This article explores rates of opioid shipments to rural and urban communties and the difficulties of intereting such data.



This article states that

> "

However previous studies note some commonalities such as:

> ""






They also point out that:

> ""

Given this need for more research to better understand why these events occur and how they could be averted, in this case study we will demonstrate how to create a resource for others to more easily and interactively access data about school shootings. To do so we will create what is called a [dashboard](https://en.wikipedia.org/wiki/Dashboard_(business)), which is a website that displays a report for a database. Dashboards summarize the data in a database and typically allow for users to interact with the data in some way.

[Here](https://beta.rstudioconnect.com/jjallaire/htmlwidgets-highcharter/htmlwidgets-highcharter.html) you can see an example of a dashboard created in R.



####[[source]](https://beta.rstudioconnect.com/jjallaire/htmlwidgets-highcharter/)


# **Main Questions**
*** 

#### {.main_question_block}
<b><u> Our main questions: </u></b>

1) What has been the yearly rate of school shootings and where have they occurred in the last 50 years (from January 1970 to June 2020)? 

2) What are the characteristics of these events?

####

# **Learning Objectives** 
*** 

In this case study, we will demonstrate how to create a [dashboard](https://en.wikipedia.org/wiki/Dashboard_(business)), which is a website that displays a report about a database. We will especially focus on using packages and functions from the [`Tidyverse`](https://www.tidyverse.org/){target="_blank"}, such as `package_name`, `package_name`. The tidyverse is a library of packages created by RStudio. While some students may be familiar with previous R programming packages, these packages make data science in R more legible and intuitive.


```{r, out.width = "20%", echo = FALSE, fig.align ="center"}
include_graphics("https://tidyverse.tidyverse.org/logo.png")
```

The skills, methods, and concepts that students will be familiar with by the end of this case study are:


Data science skills:  
  
1. Importing text from a Google Sheets document (`googlesheets4`)  
2. Converting date formats (`lubridate`)  
3. Geocoding data (`ggmap`)  and creating a jitter for geocoded data on a map (`SF`)
4. How to reshape data by pivoting between "long" and "wide" formats and drop rows with `NA` values (`tidyr`)  
5. How to create data visualizations with `ggplot2` 
6. An introductory understand of R Markdown  
7. How to create an interactive table (`DT`)  
8. How to create a map (`leaflet`)  
9. How to create an interactive dashboard with `flexdashboard` and `shiny`  

Statistical concepts and methods:  
  
1. Calculating percentages for data with missing values  

*** 


We will begin by loading the packages that we will need:


```{r}
library(httr)
library(jsonlite)
library(here)
library(readr)
library(magrittr)
library(dplyr)
library(tidyr)
library(readxl)
library(naniar)

library(devtools)
library(usethis)
library(tidyverse)
library(openintro)
#library(arcos)
library(ggiraph)
library(ggpubr)
library(ggfortify)
library(ggpol)
library(lme4)
library(formattable)
library(reshape2)
```



 <u>**Packages used in this case study:** </u>

Package   | Use in this case study                                                                      
---------- |-------------
[here](https://github.com/jennybc/here_here){target="_blank"}       | to easily load and save data  
[readr](https://readr.tidyverse.org/) |  to import the data  as a csv file  
[googlesheets4](https://googlesheets4.tidyverse.org/) | to import directly from Google Sheets
[tibble](https://tibble.tidyverse.org/) | to create tibbles (the tidyverse version of dataframes)
[dplyr](https://dplyr.tidyverse.org/){target="_blank"}      | to filter, subset, join, add rows to, and modify the data  
[stringr](https://stringr.tidyverse.org/){target="_blank"}      | to manipulate  character strings within the data (collapsing strings together, replace values, and detect values)
[magrittr](https://magrittr.tidyverse.org/){target="_blank"}      | to pipe sequential commands 
[tidyr](https://tidyr.tidyverse.org/){target="_blank"}      | to change the shape or format of tibbles to wide and long, to drop rows with `NA` values, and to see the last few columns of a tibble
[ggmap](https://cran.r-project.org/web/packages/ggmap/ggmap.pdf) | to geocode the data (which means get the latitude and longitude values)
[sf](https://r-spatial.github.io/sf/) | to modify the geocoded data so that overlapping points did not overlap
[lubridate](https://lubridate.tidyverse.org/) | to work with the data-time data    
[DT](https://rstudio.github.io/DT/) | to create the interactive table  
[htmltools](https://www.rdocumentation.org/packages/htmltools/versions/0.5.0) | to add a caption to our interactive table 
[ggplot2](https://ggplot2.tidyverse.org/){target="_blank"}      | to create plots  
[ggforce](https://cran.r-project.org/web/packages/ggforce/ggforce.pdf)   | to create a plot zoom
[forcats](https://forcats.tidyverse.org/){target="_blank"}      | to reorder factor for plot
[waffle](https://github.com/hrbrmstr/waffle) | to make waffle proportion plots  
[poliscidata](https://cran.r-project.org/web/packages/poliscidata/poliscidata.pdf) | to get population values for the states
[flexdashboard](https://rmarkdown.rstudio.com/flexdashboard/)     | to create the dashboard  
[shiny](https://shiny.rstudio.com/){target="_blank"}      | to allow our dashboard to be interactive   
[leaflet](https://rstudio.github.io/leaflet/shiny.html) | to implement the [leaflet](http://leafletjs.com/) (a JavaScript library for maps) to create the map for our dashboard   

The first time we use a function, we will use the `::` to indicate which package we are using. Unless we have overlapping function names, this is not necessary, but we will include it here to be informative about where the functions we will use come from.


# **Context**
*** 

According to this [article](https://www.cdc.gov/mmwr/volumes/68/wr/mm6802a1.htm?s_cid=mm6802a1_w) from the [Morbidity and Mortality Weekly Report (MMWR)](https://www.cdc.gov/mmwr/about.html) of the [Centers for Disease Control and Prevention (CDC)](https://en.wikipedia.org/wiki/Centers_for_Disease_Control_and_Prevention)

> Drug overdose is the leading cause of unintentional injury-associated death in the United States.



https://lancasteronline.com/news/local/report-compares-drug-overdoses-to-other-causes-of-death-in-the-us/article_24efaa58-dc50-11e7-869e-f39fbf46bfa2.html


According to this [article](https://www.cdc.gov/mmwr/volumes/67/wr/mm675152e1.htm?s_cid=mm675152e1_w) 


```{r}
knitr::include_graphics("https://www.cdc.gov/mmwr/volumes/67/wr/figures/mm675152e1-F.gif")

```

[[source]](https://www.cdc.gov/mmwr/volumes/67/wr/figures/mm675152e1-F.gif)

```{r}
knitr::include_graphics(here::here("img", "context.png"))

```

##### [[source]](https://www.cdc.gov/mmwr/volumes/68/wr/pdfs/mm6802a1-H.pdf)
 
https://www.cdc.gov/nchs/products/databriefs/db356.htm






 
# **Limitations**
*** 
There are some important considerations regarding this data analysis to keep in mind: 

According to the [Washington Post data](https://www.washingtonpost.com/national/2019/07/18/how-download-use-dea-pain-pills-database/ about the DEA data:

>"It’s important to remember that the number of pills in each county does not necessarily mean those pills went to people who live in that county. The data only shows us what pharmacies the pills are shipped to and nothing else."

Furthermore, we define counties as being rural or urban however there can be great variation within a county and we used land area values form only 2010 even though these can fluctuate. Therefore the way we categorized counties should be seen as an approximation.


# **What are the data?**
*** 

We will use data from two sources:

1) The US census for land area of counties to allow us to extimate county-level population density  

2) The [Washington Post data](https://www.washingtonpost.com/national/2019/07/18/how-download-use-dea-pain-pills-database/)from the [Drug Enforcement Administration (DEA)](https://www.dea.gov/) about opioid ([oxycodone](https://www.dea.gov/sites/default/files/2020-06/Oxycodone-2020_0.pdf) and [hydrocodone](https://www.deadiversion.usdoj.gov/drug_chem_info/hydrocodone.pdf)) pill shipments to pharmacies and paractitionaers around the US at the county-level

This dataset was released in July of 2019 and has been controversial as according to the Washington Post:

> The disclosure is part of a civil action brought by 2,500 cities, towns, counties and tribal nations alleging that nearly two dozen drug companies **conspired to saturate the nation with opioids**.

See [here](https://www.washingtonpost.com/national/2019/07/20/opioid-files/?arc404=true) for more details about how this database was released.

The [Washington Post](https://www.washingtonpost.com/national/2019/07/18/how-download-use-dea-pain-pills-database/)states that they:
>.. cleaned the data to include only information on shipments of oxycodone and hydrocodone pills. We did not include data on 10 other opioids because they were shipped in much lower quantities...

>It’s important to remember that the number of pills in each county does not necessarily mean those pills went to people who live in that county. The data only shows us what pharmacies the pills are shipped to and nothing else.

This data was part of the [Automated Reports and Consolidated Ordering System (ARCOS)]https://www.deadiversion.usdoj.gov/arcos/retail_drug_summary/ of the DEA in which:

> manufacturers and distributors report their controlled substances transactions

Their [website](https://www.deadiversion.usdoj.gov/arcos/index.html#background) indicates that: 
> The Controlled Substances Act of 1970  created the requirement for Manufacturers and Distributors to report their controlled substances transactions to the Attorney General. The Attorney General delegates this authority to the Drug Enforcement Administration (DEA).

> ARCOS is an automated, comprehensive drug reporting system which monitors the flow of DEA controlled substances from their point of manufacture through commercial distribution channels to point of sale or distribution at the dispensing/retail level - hospitals, retail pharmacies, practitioners, mid-level practitioners, and teaching institutions. Included in the list of controlled substance transactions tracked by ARCOS are the following: All Schedules I and II materials (manufacturers and distributors); Schedule III narcotic and gamma-hydroxybutyric acid (GHB) materials (manufacturers and distributors); and selected Schedule III and IV psychotropic drugs (manufacturers only).

The annual report about the data from 2019, can be found [here](https://www.deadiversion.usdoj.gov/arcos/retail_drug_summary/report_yr_2019.pdf).

As this is a very large dataset, thus the Washington Post created an [application prgoramming interface (API)](https://en.wikipedia.org/wiki/API)  to make it easier for users to access the data. 

An API is a computational interface that simplifies interactacts with a data or file system for a user. It is similar to a [Graphical User Interface GUI](https://en.wikipedia.org/wiki/Graphical_user_interface), yet it allows the user some more flexibility/functionality.


This [link](https://arcos-api.ext.nile.works/__swagger__/) takes you to the Washington Post ARCOS API. 

There was also an R package on cran called [arcos](https://cran.r-project.org/package=arcos) for interacting with the API, but this has been archived.  This package is however still available [here](https://github.com/wpinvestigative/arcos) on Github.

See [here](https://www.washingtonpost.com/national/2019/07/18/how-download-use-dea-pain-pills-database/) for more information about how to access the Washington Post DEA database.


# **Data Import**
*** 

## Land Area

We will also need land area data for our calculations of population density. 

We obtained county land area data from the US census Bureau at this [link](https://www.census.gov/library/publications/2011/compendia/usa-counties-2011.html#LND)

This [link](https://www.census.gov/library/publications/2011/compendia/usa-counties-2011/file-layout.html) explains how the data is formated.

We will use the `read_excel()` function of the `readxl` package to import the data.

```{r}
land <- readxl::read_excel(here::here("data", "LND01.xls"))
land <- as_tibble(land)

head(land)
```








## Accessing APIs

The `httr` package formats what are called "GET requests" so that they will work properly.
The `jsonlite` package alows you to convert the data from `JSON` to a differet format that is easier to work with.

APIs typically require a password or key to gain access. Thus the `httr` package helps to authenticate your data request. Often these keys are something that you do not want to share, unless the API is public.

In our case the [API](https://arcos-api.ext.nile.works/__swagger__/) is indeed public, and currently "uO4EK6I" is publicly published as a key to use on the [github page](https://github.com/wpinvestigative/arcos) for the `arcos` package. We will use that here to access the API.


## Population Data

We are interested in the county level data - first let's get the population data. We can access it by:

1) Pressing the `GET` button on the API.

```{r}
knitr::include_graphics(here::here("img", "get.png"))

```

2) Pressing the "Try it out" button.

```{r}
knitr::include_graphics(here::here("img", "tryitout.png"))
```

3) Entering the key (which we got from [here]([github page](https://github.com/wpinvestigative/arcos))).

```{r}
knitr::include_graphics(here::here("img", "key.png"))
```

4) Clicking the "Execute" button.

```{r}
knitr::include_graphics(here::here("img", "execute.png"))
```

This gives us the following output:

`curl -X GET "https://arcos-api.ext.nile.works/v1/county_population?key=uO4EK6I" -H  "accept: application/json"`

We can copy the URL section `"https://arcos-api.ext.nile.works/v1/county_population?key=uO4EK6I"` and use it in the `GET()` function of the `httr` package (note that some of the data will take longer ):

```{r}
county_pop_json<-httr::GET(url = "https://arcos-api.ext.nile.works/v1/county_population?key=uO4EK6I")
```

If we needed to specify a username and password, we would do so using the `authenticate()` function of the `httr` package within the `GET` function. The `authenticate()` function takes `user`, `password` and `type` arguments.


Now we have a [JavaScript Object Notation (JSON)](https://fileinfo.com/extension/json#:~:text=A%20JSON%20file%20is%20a,web%20application%20and%20a%20server.) file of the data. 

JSON files are [lightweight](https://en.wikipedia.org/wiki/Lightweight_programming_language) meaning that they dont take up much memory and they are human readible files to make transmitting data from websites easier.


```{r}
county_pop_json
```
Here we can see that the object called `countyjson` is a `json` object. You will also see that the `Satus` is `200`, which means that we were sucessful in retreiving the data from the API.

Now we can use the `content()` funtion of the `httr` package to extract the text from the file:

```{r}
county_pop_text <-httr::content(county_pop_json, "text")
```


Now to get the data into a more readible format , we can use the `fromJSON()` function of the `jsonlite` package. We will also convert the data into a [tibble](https://tibble.tidyverse.org/) (which is a the tidyverse version of a data frame) by using the `as_tibble()` function of the `tibble` package.

```{r}
county_pop <- jsonlite::fromJSON(county_pop_text, flatten = TRUE)
county_pop <- tibble::as_tibble(county_pop)
```

We can use the `glimpse()` function and the `distinct()` function of the `dplyr` package to get a better sense of the data. The `distinct()` function allows us to take a look at the unique values of the `year` variable.

```{r}
dplyr::glimpse(county_pop)


dplyr::distinct(county_pop,year)

```

It looks like we have data from 2006-2014.


```{r, eval = FALSE, echo = FALSE}
write.csv(county_pop, file = here::here("data", "county_pop_arcos.csv"))
save(county_pop, file =  here::here("data", "county_pop_arcos.rda"))
```

```{r, echo = FALSE}
load(here::here("data", "county_pop_arcos.rda"))
```

We are also interested in opioid pill shipment data at the county level. 

## Monthly Shipment Data

Here is the result of the same steps using the API for this data:

`curl -X GET "https://arcos-api.ext.nile.works/v1/combined_county_monthly?key=uO4EK6I" -H  "accept: application/json"`

Again, we can copy the URL section `"https://arcos-api.ext.nile.works/v1/combined_county_monthly?key=uO4EK6I"` and use it in the `GET()` function of the `httr` package (note that this may take a minute as this is larger data):

```{r, eval = FALSE}
countyjson <- httr::GET(url = "https://arcos-api.ext.nile.works/v1/combined_county_monthly?key=uO4EK6I")
countyjson_text <-httr::content(countyjson, "text")
county <- jsonlite::fromJSON(countyjson_text, flatten = TRUE)
monthlyDosage <- tibble::as_tibble(county)
```

```{r, echo = FALSE, eval = FALSE}
write.csv(monthlyDosage, file = here::here("data", "county_monthly.csv"))
save(monthlyDosage, file =  here::here("data", "county_monthly.rda"))
```

```{r, echo = FALSE}
load(here::here("data", "county_monthly.rda"))
```

Now let's ta
```{r}
glimpse(monthlyDosage)
distinct(monthlyDosage, year)

```
Looks like we have the same years of data.

## Annual Shipment Data

From the API we get the following output for the combined_county_annual data `curl -X GET "https://arcos-api.ext.nile.works/v1/combined_county_annual?key=uO4EK6I" -H  "accept: application/json"`

```{r, eval = FALSE}
county_annual_json<-httr::GET(url =  "https://arcos-api.ext.nile.works/v1/combined_county_annual?key=uO4EK6I")
county_annual_json_text <-httr::content(county_annual_json, "text")
county_annual <- jsonlite::fromJSON(county_annual_json_text, flatten = TRUE)
annualDosage <- tibble::as_tibble(county_annual)
```

```{r, echo = FALSE, eval = FALSE}
write.csv(annualDosage, file = here::here("data", "county_annual.csv"))
save(annualDosage, file =  here::here("data", "county_annual.rda"))
```

```{r, echo=FALSE}
load(here::here("data", "county_annual.rda"))
```


```{r}
glimpse(annualDosage)
```

Looks good. 


# **Data Exploration**
***

Now let's take a deaper look at the data to see if we have any missing data using the `naniar` package.

We can use the `vis_miss()` function to create a plot of missing data.

Let's start with the land area data.
```{r}
naniar:: vis_miss(land)
```
Looks like there is no missing data.

How about the population data:

```{r}
vis_miss(county_pop)
```
We are missing some values for the `Name` and `variable` data, but we don`t intend to use these, so this should be ok. It is however a good idea to check these rows to see if anything strange is happening.

Let's use the `filter()` function of the `dplyr` package and the `is.na()` base function to see more about the data that does not have countyfips codes.

We will also start using the `%>%` pipe of the `magrittr` package for our assignments.


<details> <summary>Click here if you are unfamiliar with piping in R, which uses this `%>%` operator</summary>  


By [piping](https://cran.r-project.org/web/packages/magrittr/vignettes/magrittr.html){target="_blank"} we mean using the `%>%` pipe operator which is accessible after loading the `tidyverse` or several of the packages within the tidyverse like `dplyr` because they load the [`magrittr` package](https://cran.r-project.org/web/packages/magrittr/vignettes/magrittr.html){target="_blank"}. 
This allows us to perform multiple sequential steps on one data input. 

***

</details> 

```{r}
county_pop %>% filter(is.na(NAME))
```
This looks ok. So let's now move on to the DEA data. We will need to use the `gg_mis_var()` function to create a simpler plot for the `monthlyDosage` data as it is too large to create the other type of figure. and we will also use the `pct_miss()` function to calculate the percentage missing. 

```{r}
vis_miss(annualDosage)
naniar::pct_miss(monthlyDosage)
naniar::gg_miss_var(monthlyDosage)
```
Interesting, we appear to be missing `countyfips` codes for a small percentage of our annual data and about 30% of our monthly data.


```{r}
annualDosage %>% filter(is.na(countyfips))
```


It looks like the missing data is data for Puerto Rico- this makes sense that it doesnt have countyfips codes.

Let's see if there is any data other than data for Puerto Rico that is also missing `countyfips` values.



```{r, eval = FALSE}
annualDosage %>% filter(is.na(countyfips)) %>%
 filter(BUYER_STATE != "PR")
```

#### {.scrollable }
```{r, echo = FALSE}
annualDosage %>% filter(is.na(countyfips)) %>%
 filter(BUYER_STATE != "PR") %>%
  # this allows us to show the full output in the rendered rmarkdown
 print(n = 1e4)
```
####

It looks like there is also data for other territories in the data set. As well as some counties with no name.


For some reason the rows for the Montgomery county of Arkansa are also missing a `countyfips` value.

```{r}
annualDosage %>% filter(is.na(countyfips)) %>%
 filter(BUYER_STATE == "AR")
```


According to this [website](https://www.nrcs.usda.gov/wps/portal/nrcs/detail/national/home/?cid=nrcs143_013697) thie fIPS code is 05097.


We will update these values in the next section.


Let's also look through our monthly data as well to make sure that we have a similar situation as the annual data:

```{r, eval = FALSE}
monthlyDosage %>% 
  filter(is.na(countyfips))
```

#### {.scrollable }
```{r, echo = FALSE}
monthlyDosage %>% 
  filter(is.na(countyfips)) %>%
  # this allows us to show the full output in the rendered rmarkdown
 print(n = 1e7)
```
####
# **Data Wrangling**
***

## Cleaning land data
We want the `LND110210D` column which is the data from the year 2010.

LND = Land Area
110 = unit square miles (subgroup-code of the group) * avocado I found this somehwere else.. the census info was vauge would like to confirm that that is indeed what the sugroup code shows us
2 = century
10 = 2010 (based on the century)
D = Data

Thus we can select the county names, the county numeric codes, and the `LND110210D`column by using the `select()` function of the `dplyr` package.

```{r}
county_area <- land %>% select(Areaname, STCOU, LND110210D)
county_area
```

 

## Updating `countyfips`

We will use the `case_when()` function of the `dplyr` package recode the `NA` values for the rows for the `MONGOMERY` county of `AR` to be `05097`. First we need to specify for these particular rows. Becuase there Montgomery may be a county name in other states, we need to evaluate when the `BUYER_STATE` is `AR` and when the `BUYER_COUNTY` is `MONTGOMERY`. We will use the `&` opperator to indcate that both conditions must be true. We will then recode the `coutryfips` values for these rows to be `"05097"` using the `~` symbol. All other values need to stay the same. Thus we need to use `TRUE ~` to recode all the other `countyfips` values to what they currently are. Otherwise these would autmatically be `NA`.

```{r}

annualDosage %<>% 
  mutate(countyfips = case_when(BUYER_STATE == "AR" & 
                               BUYER_COUNTY == "MONTGOMERY" ~ as.character("05097"),
                               TRUE ~ countyfips))

```

Now we can check that we indeed fixed our data.

```{r}
annualDosage %>% 
  filter(is.na(countyfips)) %>%
  filter(BUYER_STATE == "AR")

annualDosage %>% 
  filter(BUYER_COUNTY == "MONTGOMERY") %>%
  filter(BUYER_STATE == "AR")
```
Great! We fixed it.


We will also check if we need to do the same four the `monthlyDosage` data.


```{r}
monthlyDosage %>% 
  filter(BUYER_COUNTY == "MONTGOMERY") %>%
  filter(BUYER_STATE == "AR")
```

Looks like we do. 

#### {.recall_code_question_block}
<b><u> Question Opportunity </u></b>

See if you can fix these rows for the `monthlyDosage` data without looking at the code for the `annualDosage` data.

####


<details> <summary> Click here to reveal the code. </summary>

```{r}
monthlyDosage %<>% 
  mutate(countyfips = case_when(BUYER_STATE == "AR" & 
                               BUYER_COUNTY == "MONTGOMERY" ~ as.character("05097"),
                               TRUE ~ countyfips))

monthlyDosage %>% 
  filter(BUYER_COUNTY == "MONTGOMERY") %>%
  filter(BUYER_STATE == "AR")
```

</details>


OK, we also had some rows that didn't have county names because they were just missing or the data was for US territories. We will remove the values that dont have county names.

First let's take a look at them agian and check the `monthlyDosage` data.

```{r}
annualDosage %>% filter(is.na(BUYER_COUNTY))
monthlyDosage %>% filter(is.na(BUYER_COUNTY))
```

We can filter out these values by using the `!` exclamation mark before the `is.na()` function.

```{r}

annualDosage %<>%  filter(!is.na(BUYER_COUNTY))
monthlyDosage %<>%  filter(!is.na(BUYER_COUNTY))

annualDosage %>% filter(is.na(BUYER_COUNTY))
monthlyDosage %>% filter(is.na(BUYER_COUNTY))

```

Let's check if our land area data has information for US territories. If not, we will remove the data for the territories in our `monthlyDosage` and `annualDosage` data. However, this would be very interesting and imporatant to investigate. We can use the `str_detect()` function of the `stringr` package, which contains lots of functions for looking for patterns in character strings, to look for data from Puerto Rico. 

***
<details> <summary> Click here for an explanation about character strings </summary>

There are several classes of data in R programming. 
Character is one of these classes. 
A character string is an individual data value made up of characters. 
This can be a paragraph, like the legend for the table, or it can be a single letter or number like the letter `"a"` or the number `"3"`. 

If data are of class character, than the numeric values will not be processed like a numeric value in a mathematical sense. 

</details>


***

The `str_detect()` function allows us to look for a particular pattern. It does not have to be the full value, there can be a partial match. Thus we can look to see if there are any `PR` strings withing the vlaues of the the `Areaname` variable. 

```{r}
county_area %>% filter(str_detect(string = Areaname, pattern = "PR"))
```

You can see using a different abbreviation, that this code does as intended:

```{r}
county_area %>% filter(str_detect(string = Areaname, pattern = "AR"))
```
OK, so it does mot look like there is any territory land area data in this dataset. Thus we will also remove these from the `annualDosage` and `monthlyDosage` tibbles.

#### {.recall_code_question_block}
<b><u> Question Opportunity </u></b>

Do you recall how to do this?

####


<details> <summary> Click here to reveal the code. </summary>
```{r}
annualDosage %<>% filter(!is.na(countyfips))
monthlyDosage %<>% filter(!is.na(countyfips))
```
</details> 



```{r}
naniar:: vis_miss(annualDosage)
```
Great! Now there is no missing data in our annual data.




## Rural and Urban Counties

Defining if a region is rural or urban is actually quite complicated as the overall population changes, the structure of our towns and cities changes, and the access between different locations changes over time. Please see this [report](https://www2.census.gov/geo/pdfs/reference/ua/Defining_Rural.pdf) form the US Census Beureau about the history of this definition. 

According to several [definitions](https://www.hrsa.gov/rural-health/about-us/definition/index.html) - urban **areas** are often defined as those with greater than 50,000 people. However, there are also
[definitions](https://www.ers.usda.gov/topics/rural-economy-population/rural-classifications/what-is-rural/) of rural areas being based on  "population densities of less than 500 people per square mile and places with fewer than 2,500 people". Typically counties are made up of multiple areas. 

The census estimates rural and urban areas around the US relatively often. However, census collections about these measuresments does not occur every year.

Thus we will define a county as rural or urban based on the population density using the USDA [definition]((https://www.ers.usda.gov/topics/rural-economy-population/rural-classifications/what-is-rural/)) that we described above:

rural  = population densities of less than 500 people per square mile, as well as places with fewer than 2,500 people   
  uban = populations densities of greater than 500 people per square mile



Ideally we would want land area from each year, as these do fluctuate a bit, however, this should be a decent approximation as 2010 is in the middle of our time span.

We will therefore calculate the density as the number of people per square mile by dividing the population values by the land area values. To do so we first need to combine our `county_area` and our `county_pop` data together. First we want to make sure that we have one column, in our case the  column that contains the numeric code for the counties, in the same format and with the same name in both the tibbles that we wish to combine. 

We can use the `rename()` function of the `dplyr` package to rename the `STCOU` column to be `countyfips`. The new name is always listed first before the old name with this function like so: `rename(new_name = old_name)`.

```{r}
county_area %<>%
  rename(countyfips = STCOU)
```


We can use the `mutate()` funtion of the `dplyr` package to make the `countyfips` variable a factor in both tibbles. 

What exactly is a factor?

***
<details> <summary> Click here for an explanation of data classes in R </summary>

There are several classes of data in R programming. 
Character is one of these classes. 
A character string is an individual data value made up of characters. 
This can be a paragraph, like the legend for the table, or it can be a single letter or number like the letter `"a"` or the number `"3"`. 

If data are of class character, than the numeric values will not be processed like a numeric value in a mathematical sense. 

If you want your numeric values to be interpreted that way, they need to be converted to a numeric class. 
The options typically used are integer (which has no decimal place) and double precision (which has a decimal place). 

A variable that is a [factor](https://www.stat.berkeley.edu/~s133/factors.html#:~:text=Conceptually%2C%20factors%20are%20variables%20in,refered%20to%20as%20categorical%20variables.&text=Factors%20in%20R%20are%20stored,when%20the%20factor%20is%20displayed.) has a set of particular values called levels. Even if these are numeric, they will be interpreted as level not as a mathematical numnber. You can modify the order of these levels with the `forcats` package.

</details>


***


```{r}
county_pop %<>%
  mutate(countyfips = as.factor(countyfips))

county_area %<>%
  mutate(countyfips = as.factor(countyfips))
```

Great! Now we are ready to combine our data together.

We can do so using one of the  `*_join()`functions of the `dplyr` package.

There are several ways to join data using the `dplyr` package.


```{r, echo = FALSE, outwidth = "50%"}
knitr::include_graphics(here::here("img", "join.png"))
```

##### [[source]](https://dplyr.tidyverse.org/reference/join.html)

Here is  a visualization of these options:

```{r, echo = FALSE, outwidth = "50%"}
knitr::include_graphics(here::here("img", "join_image.png"))
```

##### [[source]](https://rstudio.com/resources/cheatsheets/)

See [here](https://dplyr.tidyverse.org/reference/join.html) for more details about joining data.

Since the population data came from the API, we probably have information about opioid pill shipments for each of the included counties. Since the land area data came from a different source, it may contain additional counties that are not in our population or drug shipment data.  Thus we will use the `left_join()` function where x in this case will be the `county_pop`  and y will be the `country_area`. Thus we will add the `LND110210D` (land area) values for all counties that match `county_pop` based on the `countyfips` column that they have in common. 


```{r}
county_info <-left_join(county_pop, county_area)
```

We are now ready to calculate the population density per square mile. We can create a new column with this data using the `mutate()` function and the `/` to divide the `population` value by the land area value (in square miles) for each county. 

```{r}
county_info %<>%
  mutate(density = population/LND110210D)

county_info
```


Great, now we are ready to create a variable that classifies if a county was rural or urban based on our definition of rural counties being those with less than 500 people per square mile as well as those with less than 2,500 people. We will use the `case_when()` function of the `dplyr` package to calssify the new `rural_urban` variable as either `"Urban"` or `"Rural"` based on the evaluations of the `density` and the `population` variables. If the density is greater than or equal to 500 people per square mile, then the county will be coded as `"Urban"`, alternatively if the density is less than 500 people per square mile or the population is less than 2500, than the county will be coded as `"Rural"`. The `|` opperator is used to indicate that either expression should result in coding the county as `"Rural"`

```{r}

county_info %<>%
  mutate(rural_urban = case_when(density  >= 500 ~ "Urban",
                                 density  < 500 | population < 2500 ~ "Rural"))
```

We can use the `count()` function of the `dplyr` package to see how many of each this resulted in:

```{r}
count(county_info, rural_urban)
```

We will now combine the `monthlyDosage` and the `annualDosage` data with the `count_info` tibble.

#### {.think_question_block}
<b><u> Question Opportunity </u></b>

How might we do this?

####


<details> <summary> Click here to reveal the code. </summary>

```{r}
monthlyDosage %<>%
  mutate(countyfips = as.factor(countyfips))


Monthly <-left_join(monthlyDosage, county_info)


annualDosage %<>%
  mutate(countyfips = as.factor(countyfips))
  
Annual <-left_join(annualDosage, county_info)

```
</details>

```{r}
glimpse(Monthly)
glimpse(Annual)
```

Great, now we should have the data that we need for the case study. 
```{r,echo= FALSE, eval = TRUE}
write.csv(Annual, file = here::here("data","Wrangled", "Annual_opioid_data.csv"))
save(Annual, file =  here::here("data","Wrangled", "Annual_opioid_data.rda"))
write.csv(Monthly, file = here::here("data","Wrangled", "Monthly_opioid_data.csv"))
save(Monthly, file =  here::here("data", "Wrangled","Monthly_opioid_data.rda"))
```

Notice how there is a variable called `DOSAGE_UNIT`. This indicates the number of pills shipped to a pharmacy in this county that were either [oxycodone](https://www.dea.gov/sites/default/files/2020-06/Oxycodone-2020_0.pdf) or [hydrocodone](https://www.deadiversion.usdoj.gov/drug_chem_info/hydrocodone.pdf).

Let's do a check to see how complete our data is. We can use the `vis_miss()` function `naniar` package to create a plot that shows if we have any missing data.

```{r}
naniar:: gg_miss_var(Annual)

naniar:: gg_miss_var(Annual)


naniar:: gg_miss_var(Monthly)


```

Need to figure this out
```{r}
Annual %>%
  filter(is.na(STATE))
```


# **Data Analysis and Visualization**
***

### How has population density changed over the years in different states?


```{r}
dens_df <- county_info  %>% group_by(BUYER_STATE, year) %>%
     summarise( mean_DENS = mean(density, na.rm = TRUE))
dens_df %<>%
rename(STATE = BUYER_STATE) %>%
  mutate(year = as.factor(year))

 ggplot(dens_df, aes(x =STATE, y = mean_DENS, col=year, group = year)) + 
  geom_point() + 
  theme_minimal()+
  theme(axis.title.x=element_blank())
```

We can see that the density is fairly similar for most states, however DC, MA, NJ, NY, RI, and VA have much higher densities. 


```{r}

 ggplot(dens_df, aes(x =year, y = log(mean_DENS), col=year, group = year)) + 
  geom_boxplot() + 
  geom_jitter(width = .1)+
  theme_minimal()+
  theme(axis.title.x=element_blank())

```



```{r}

dens_df <- county_info  %>% group_by( year) %>%
     summarise( mean_DENS = mean(density, na.rm = TRUE))
dens_df %<>%
  mutate(year = as.factor(year))

 ggplot(dens_df, aes(x =year, y = mean_DENS)) + 
  geom_point() +
  geom_smooth() +
  theme_minimal()+
  theme(axis.title.x=element_blank())
```

The density doesn't appear to change that much from 2006 to 2014. 


### How have the number of rural and urban areas changed over years?

```{r}

R_U <- county_info  %>% group_by( year) %>%
     count(rural_urban)

 ggplot(R_U, aes(x =year, y =n, col=rural_urban, group =rural_urban)) + 
  geom_point() + 
   geom_smooth()+
   facet_wrap(~rural_urban, scales = "free")+
  theme_minimal()+
  theme(axis.title.x=element_blank())
```


```{r, eval = FALSE}

cnt <- bind_cols(dfCSS %>% count(UB10) %>% select( Urban = UB10, count10 = n) ,
         dfCSS %>% count(UB11) %>% select( count11 = n) ,
         dfCSS %>% count(UB12) %>% select( count12 = n) ,
         dfCSS %>% count(UB13) %>% select( count13 = n),
         dfCSS %>% count(UB14) %>% select( count14 = n) ) %>% 
        mutate( Urban = as.factor(Urban) )

formattable( cnt,list( 
`count11` = formatter("span",  style = ~ style(color = 
   ifelse(`count11`>`count10`, "red", "green")), 
  ~ icontext(ifelse(`count11`>`count10`,"arrow-up", "arrow-down"), `count11`) ),
`count12` = formatter("span",  style = ~ style(color = 
   ifelse(`count12`>`count11`, "red", "green")), 
  ~ icontext(ifelse(`count12`>`count11`,"arrow-up", "arrow-down"), `count12`) ),
 `count13` = formatter("span",  style = ~ style(color = 
   ifelse(`count13`>`count12`, "red", "green")), 
  ~ icontext(ifelse(`count13`>`count12`,"arrow-up", "arrow-down"), `count13`) ),
 `count14` = formatter("span",  style = ~ style(color = 
   ifelse(`count14`>`count13`, "red", "green")), 
  ~ icontext(ifelse(`count14`>`count13`,"arrow-up", "arrow-down"), `count14`) )
 ) )

```





# **Summary**
*** 

## Summary Plot

## Synopsis

In this case study we have demonstrated the basics of R Markdown and how to create a dashboard with using the `flexdashboard` package. We also demonstrated how to include an interactive table with the `DT` package, how to include interactive plots using functions of the `shiny` package such as `renderPlot()`. We also included interactive value boxes using the `renderValueBox()` function of the `flexdashboard` package which works with the `shiny` package. Finally we also showed how to include interactive maps using the `leaflet` package. 

This case study also explored how to properly calculate and interpret percentages when the data has missing values. We also discussed the benefits and limiting aspects of pie charts (using `ggplot2`) and waffle plots (using `waffle`).

Overall the dashboard that we created shows that the number of shootings per year has increased overtime. Further investigation is necessary to determine if this is simply due to increases in population alone or if the rate has increased due to other factors and if so, what those factors might be. It is also clear that the number of shootings and the number of deaths per capita varies by state. Thus there appears to be other aspects accounting for state differences. 

# **Suggested Homework**
*** 

Create another dashboard with graphs and statistics featuring other elements within this dataset. For example, students may create graphs that explore what school events are reported to have more shootings.


# **Additional Information**
***

## Helpful Links

[RStudio](https://rstudio.com/products/rstudio/features/){target="_blank"}  
[Cheatsheet on RStuido IDE](https://github.com/rstudio/cheatsheets/raw/master/rstudio-ide.pdf){target="_blank"}  
[Other RStudio cheatsheets](https://rstudio.com/resources/cheatsheets/){target="_blank"}   
[RStudio projects](https://r4ds.had.co.nz/workflow-projects.html)

[Tidyverse](https://www.tidyverse.org/){target="_blank"}   

   

[Piping in R](https://cran.r-project.org/web/packages/magrittr/vignettes/magrittr.html){target="_blank"}   

[String manipulation cheatsheet](https://rstudio.com/resources/cheatsheets/){target="_blank"}  
[Table formats](https://en.wikipedia.org/wiki/Wide_and_narrow_data){target="_blank"}

[Geocoding](https://en.wikipedia.org/wiki/Geocoding)  
[Coordinate reference system (CRS)](https://www.w3.org/2015/spatial/wiki/Coordinate_Reference_Systems) [ESPG](https://en.wikipedia.org/wiki/EPSG_Geodetic_Parameter_Dataset)
[World Geodetic System (WGS) version 84 also called ESPG:4326 ](https://en.wikipedia.org/wiki/World_Geodetic_System#WGS84)   
[Albers equal-area conic projection](https://en.wikipedia.org/wiki/Albers_projection#:~:text=The%20Albers%20equal%2Darea%20conic,that%20uses%20two%20standard%20parallels.&text=The%20Albers%20projection%20is%20used,the%20United%20States%20Census%20Bureau.)   
[crs 102008](https://spatialreference.org/ref/esri/102008/html/)  

To learn more about geospatial coordinate systems see [here](https://www.nceas.ucsb.edu/sites/default/files/2020-04/OverviewCoordinateReferenceSystems.pdf) and [here](https://guides.library.duke.edu/r-geospatial/CRS).


[`ggplot2` package](http://ggplot2.tidyverse.org){target="_blank"}    
Please see [this case study](https://opencasestudies.github.io/ocs-bp-co2-emissions/)  for more details on using `ggplot2`    
[grammar of graphics](http://vita.had.co.nz/papers/layered-grammar.html){target="_blank"}   
[`ggplot2` themes](https://ggplot2.tidyverse.org/reference/ggtheme.html){target="_blank"}   

[Motivating article for this case study about school shootings](https://link.springer.com/content/pdf/10.1007/s11920-012-0331-6.pdf)

Also see this [article](https://siepr.stanford.edu/sites/default/files/publications/19-036.pdf) to learn more about the impacts of school shootings.


[Lightweight markup languages(LML)](https://en.wikipedia.org/wiki/Lightweight_markup_language)  
[Markdown](https://en.wikipedia.org/wiki/Markdown)  
[R markdown](http://rmarkdown.rstudio.com/)   
[`knitr`](https://yihui.org/knitr/)  
[`rmarkdown` (package)](https://cran.r-project.org/web/packages/rmarkdown/rmarkdown.pdf)

See this [book](https://bookdown.org/yihui/rmarkdown/) for more information on working with R Markdown files. 

The RStudio [cheatsheet for R Markdown](https://github.com/rstudio/cheatsheets/raw/master/rmarkdown-2.0.pdf) and this [tutorial](https://ourcodingclub.github.io/tutorials/rmarkdown/) are great for getting started. 

[Pandoc](https://en.wikipedia.org/wiki/Pandoc)  

[YAML](https://en.wikipedia.org/wiki/YAML)  
[Configuration](https://en.wikipedia.org/wiki/Configuration_file)  

[flexdashboard](https://rmarkdown.rstudio.com/flexdashboard/)  

See [here](https://rstudio.com/resources/webinars/introducing-flexdashboards/) for a video about flexdashboard and [here](https://rmarkdown.rstudio.com/flexdashboard/) for a more information on how to use this package.   
See [here](https://rmarkdown.rstudio.com/flexdashboard/using.html#components) for a list of other packages that are useful for adding elements to dashboards created with the `flexdashboard` package.   
See [here](https://www.datadreaming.org/post/r-markdown-theme-gallery/) for a list of R Markdown themes which can be used with `flexdashbard`.   
See [Font Awesome](https://fontawesome.com/icons?d=gallery) for icons.  

To learn more about using `shiny` with the `flexdashboard` package to create interactive dashboards, see this [tutorial](https://rmarkdown.rstudio.com/flexdashboard/shiny.html).   

[leaflet (R package)](https://rstudio.github.io/leaflet/)   
[Leaflet (JavaScript Library)](https://leafletjs.com/)   

[shiny](https://shiny.rstudio.com/)  
See [here](https://shiny.rstudio.com/gallery/) for a gallery of `shiny` examples.

See this [website](https://rstudio.github.io/shinydashboard/) to learn about a more flexible and slightly more challenging option for creating dashboards in R using a package called `shinydashboard`.


<u>**Packages used in this case study:** </u>

Package   | Use in this case study                                                                      
---------- |-------------
[here](https://github.com/jennybc/here_here){target="_blank"}       | to easily load and save data  
[readr](https://readr.tidyverse.org/) |  to import the data  as a csv file  
[googlesheets4](https://googlesheets4.tidyverse.org/) | to import directly from Google Sheets
[tibble](https://tibble.tidyverse.org/) | to create tibbles (the tidyverse version of dataframes)
[dplyr](https://dplyr.tidyverse.org/){target="_blank"}      | to filter, subset, join, add rows to, and modify the data  
[stringr](https://stringr.tidyverse.org/){target="_blank"}      | to manipulate  character strings within the data (collapsing strings together, replace values, and detect values)
[magrittr](https://magrittr.tidyverse.org/){target="_blank"}      | to pipe sequential commands 
[tidyr](https://tidyr.tidyverse.org/){target="_blank"}      | to change the shape or format of tibbles to wide and long, to drop rows with `NA` values, and to see the last few columns of a tibble
[ggmap](https://cran.r-project.org/web/packages/ggmap/ggmap.pdf) | to geocode the data (which means get the latitude and longitude values)
[sf](https://r-spatial.github.io/sf/) | to modify the geocoded data so that overlapping points did not overlap
[lubridate](https://lubridate.tidyverse.org/) | to work with the data-time data    
[DT](https://rstudio.github.io/DT/) | to create the interactive table  
[htmltools](https://www.rdocumentation.org/packages/htmltools/versions/0.5.0) | to add a caption to our interactive table 
[ggplot2](https://ggplot2.tidyverse.org/){target="_blank"}      | to create plots  
[ggforce](https://cran.r-project.org/web/packages/ggforce/ggforce.pdf)   | to create a plot zoom
[forcats](https://forcats.tidyverse.org/){target="_blank"}      | to reorder factor for plot
[waffle](https://github.com/hrbrmstr/waffle) | to make waffle proportion plots  
[poliscidata](https://cran.r-project.org/web/packages/poliscidata/poliscidata.pdf) | to get population values for the states
[flexdashboard](https://rmarkdown.rstudio.com/flexdashboard/)     | to create the dashboard  
[shiny](https://shiny.rstudio.com/){target="_blank"}      | to allow our dashboard to be interactive   
[leaflet](https://rstudio.github.io/leaflet/shiny.html) | to implement the [leaflet](http://leafletjs.com/) (a JavaScript library for maps) to create the map for our dashboard   


#### {.emphasis_block}

**Warning Signs**

From [Sandy Hook Promise](https://www.sandyhookpromise.org/gun-violence/know-the-signs-of-gun-violence/)...

Here is a list of potential warning signs that can signal an individual may be in crisis and/or need help:

+ Suddenly withdrawing from people and activities
+ Consistent bullying or intimidating others, or being bullied by others
+ Extreme mood or personality changes
+ Victim of constant social rejection
+ Talking about plans or actively making plans to harm themselves or others
+ Bringing a weapon to school – or threatening or talking about doing so
+ Bragging about or warning others about an upcoming act of violence
+ Recruiting others to join in a planned act of violence
+ Warning students to stay away from school or events
+ Expressing fascination with guns and/or school shootings
+ Expressing hopelessness about the future
+ Extreme, prolonged sadness or distress
+ Expressing or showing feelings of isolation
+ Bragging about access to guns

**NOTE**

This list is not a comprehensive list of warning signs nor does exhibiting one of these signs indicate imminent violence.

When concerned about seeing troubling behaviors, tell a trusted adult or call 911, if there is an immediate threat.

**Respond to Warning Signs**

Call 911 if you feel there is an immediate threat. 

Call [+1-844-5-SAYNOW](tel:18445729669) if you would to submit an anonymous safety concern.


If you or your child or student experienced a shooting please see this [website](https://kidshealth.org/en/parents/ptsd.html) and this [website](https://www.verywellmind.com/shooting-ptsd-from-a-shooting-2797200) for guidance about dealing with the trauma.


####

## Session Info

```{r}
sessionInfo()
```


## Acknowledgements

We would like to acknowledge [Elizabeth Stuart](https://www.jhsph.edu/faculty/directory/profile/1792/elizabeth-a-stuart) for assisting in framing the major direction of the case study.

We would also like to acknowledge the [Bloomberg American Health Initiative](https://americanhealth.jhu.edu/) for funding this work. 

